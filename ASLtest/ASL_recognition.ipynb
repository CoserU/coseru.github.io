{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ASL_recognition.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "S7Pozv7Tuikk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Download the dataset to Colab."
      ]
    },
    {
      "metadata": {
        "id": "gTEmsoIsulGR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Add codes for downloading the dataset\n",
        "!unzip -q dataset_ASL.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UlmeOiKdudDx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Preparing the Data"
      ]
    },
    {
      "metadata": {
        "id": "qejXX4I_A2Yo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, we make sure that the colab runtime type is Python 3 with GPU. Then we import tensorflow, Keras layers and other packages."
      ]
    },
    {
      "metadata": {
        "id": "1ZlQJIhVAlgh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, DepthwiseConv2D, Flatten, BatchNormalization, ReLU, AveragePooling2D, Add\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u3cN_VTnA7Qu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now letâ€™s take a look at the images. They are of different sizes and different aspect ratios."
      ]
    },
    {
      "metadata": {
        "id": "byoPwMHTA489",
        "colab_type": "code",
        "outputId": "add54a8e-d152-49ee-b4c8-2d78d815cc3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "cell_type": "code",
      "source": [
        "# Training directory and validation directory\n",
        "train_path = 'dataset_ASL/train/'\n",
        "valid_path = 'dataset_ASL/validation/'\n",
        "\n",
        "def show_image_from_path(data_path, alphabet):\n",
        "    folder_path = os.path.join(data_path, alphabet)\n",
        "    img_files = os.listdir(folder_path)\n",
        "    img_file = img_files[np.random.choice(len(img_files), 1)[0]]\n",
        "    img = plt.imread(os.path.join(folder_path, img_file))\n",
        "    plt.imshow(img)\n",
        "    \n",
        "# Show a image randomly picked with label 'a'\n",
        "show_image_from_path(train_path, 'a')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMcAAAD7CAYAAADevYAQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5ADpbo5OOjlAupujk04OkP8HfgvlP92EDEYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ysA6VDIfBXFn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "There are 24 fingerspelled alphabets in the dataset. We need to convert the alphabetical labels to integer labels for model training."
      ]
    },
    {
      "metadata": {
        "id": "03Zrf8CFBHGF",
        "colab_type": "code",
        "outputId": "2b4d3bad-764f-40bf-cbc6-27cfda1bc0e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "# Alphabet to integer\n",
        "alphabet2int = {}\n",
        "for i, char in enumerate('abcdefghiklmnopqrstuvwxy'):\n",
        "    alphabet2int[char] = i\n",
        "print(alphabet2int)\n",
        "\n",
        "# Integer to alphabet\n",
        "int2alphabet = {val: key for key, val in alphabet2int.items()}\n",
        "print(int2alphabet)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'k': 9, 'l': 10, 'm': 11, 'n': 12, 'o': 13, 'p': 14, 'q': 15, 'r': 16, 's': 17, 't': 18, 'u': 19, 'v': 20, 'w': 21, 'x': 22, 'y': 23}\n",
            "{0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'k', 10: 'l', 11: 'm', 12: 'n', 13: 'o', 14: 'p', 15: 'q', 16: 'r', 17: 's', 18: 't', 19: 'u', 20: 'v', 21: 'w', 22: 'x', 23: 'y'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "070tFRH7BdIY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here, we will use the `tf.data` API to preprocess the images and build the training/validation datasets. First we get the paths for all images and the corresponding integer labels."
      ]
    },
    {
      "metadata": {
        "id": "K7SQxkXhBcTq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get the image paths and the corresponding integer labels\n",
        "def get_paths_labels(data_path):\n",
        "    paths = []\n",
        "    labels = []\n",
        "    for class_folder in os.listdir(data_path):\n",
        "        folder_path = os.path.join(data_path, class_folder)\n",
        "        label = alphabet2int[class_folder]\n",
        "        for img_path in os.listdir(folder_path):\n",
        "            paths.append(os.path.join(folder_path, img_path))\n",
        "            labels.append(label)\n",
        "    return np.array(paths), np.array(labels)\n",
        "\n",
        "train_paths, train_labels = get_paths_labels(train_path)\n",
        "valid_paths, valid_labels = get_paths_labels(valid_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wt46pCuYBlxE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Then we randomly shuffle the training paths/labels and validation paths/labels."
      ]
    },
    {
      "metadata": {
        "id": "OkEGjoAYBjYE",
        "colab_type": "code",
        "outputId": "b1bd662c-ef92-4f4c-b5f2-fa0322a75bd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# Shuffle the paths/labels\n",
        "p = np.random.permutation(len(train_labels))\n",
        "train_paths, train_labels = train_paths[p], train_labels[p]\n",
        "\n",
        "p = np.random.permutation(len(valid_labels))\n",
        "valid_paths, valid_labels = valid_paths[p], valid_labels[p]\n",
        "\n",
        "n_train, n_valid = len(train_labels), len(valid_labels)\n",
        "print('The size of the training set is {}'.format(n_train)) # 2400 images\n",
        "print('The size of the validation set is {}'.format(n_valid)) # 600 images"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The size of the training set is 2400\n",
            "The size of the validation set is 600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f8OAYP4VBqP0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here we set the size of the input image as 224*224 for MobileNetV2. For simplicity, we assume the image mean is 0.5 for preprocessing and use 32 as the batch size for both training and validation."
      ]
    },
    {
      "metadata": {
        "id": "mCyP01T4Bn45",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_size = 224\n",
        "RGB_mean = np.array([0.5, 0.5, 0.5])\n",
        "BATCH_SIZE = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "32TnxjmPByAw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Training Dataset"
      ]
    },
    {
      "metadata": {
        "id": "M4uM0WFvB-cg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Preprocessing steps for training:\n",
        "\n",
        "* Decode the png-encoded image.\n",
        "* Resize the image to 256*256 with padding to keep the same aspect ratio.\n",
        "* Randomly crop the image to 224*224. The camera sometimes cannot capture the whole gesture, so this data augmentation method lets our model to learn to predict without a complete gesture.\n",
        "* Randomly flip the image horizontally to learn both right-handed and left-handed gestures.\n",
        "* Normalize the image tensor."
      ]
    },
    {
      "metadata": {
        "id": "SqocsxMaBu2t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load and preprocess the images for the training dataset\n",
        "def preprocess_train_image(image):\n",
        "    image = tf.image.decode_png(image, channels=3)\n",
        "    image = tf.image.resize_image_with_pad(image, 256, 256)\n",
        "    image = tf.image.random_crop(image, [image_size, image_size, 3])\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image /= 255.0\n",
        "    image -= RGB_mean\n",
        "    return image\n",
        "\n",
        "def load_and_preprocess_train_image(path):\n",
        "    image = tf.read_file(path)\n",
        "    return preprocess_train_image(image)\n",
        "\n",
        "train_path_ds = tf.data.Dataset.from_tensor_slices(train_paths)\n",
        "train_image_ds = train_path_ds.map(load_and_preprocess_train_image)\n",
        "train_label_ds = tf.data.Dataset.from_tensor_slices(train_labels)\n",
        "\n",
        "# Zip the images and labels together\n",
        "train_image_label_ds = tf.data.Dataset.zip((train_image_ds, train_label_ds))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wY68I7JMCOJe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Then we set the buffer size and the batch size for training."
      ]
    },
    {
      "metadata": {
        "id": "CpWdw7coCMA1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Prepare for training\n",
        "tr_ds = train_image_label_ds.repeat()\n",
        "tr_ds = tr_ds.shuffle(buffer_size=1000)\n",
        "tr_ds = tr_ds.batch(BATCH_SIZE)\n",
        "tr_ds = tr_ds.prefetch(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EUawxMOTCV9X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Validation Dataset"
      ]
    },
    {
      "metadata": {
        "id": "sO1N0wweCX6B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Preprocessing steps for validation:\n",
        "\n",
        "* Decode the png-encoded image.\n",
        "* Resize the image to 224*224 with padding to keep the same aspect ratio.\n",
        "* Normalize the image tensor."
      ]
    },
    {
      "metadata": {
        "id": "7jL3Puk2CTfG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load and preprocess the images for the validation dataset\n",
        "def preprocess_test_image(image):\n",
        "    image = tf.image.decode_png(image, channels=3)\n",
        "    image = tf.image.resize_image_with_pad(image, image_size, image_size)\n",
        "    image /= 255.0\n",
        "    image -= RGB_mean\n",
        "    return image\n",
        "\n",
        "def load_and_preprocess_test_image(path):\n",
        "    image = tf.read_file(path)\n",
        "    return preprocess_test_image(image)\n",
        "\n",
        "valid_path_ds = tf.data.Dataset.from_tensor_slices(valid_paths)\n",
        "valid_image_ds = valid_path_ds.map(load_and_preprocess_test_image)\n",
        "valid_label_ds = tf.data.Dataset.from_tensor_slices(valid_labels)\n",
        "\n",
        "# Zip the images and labels together\n",
        "valid_image_label_ds = tf.data.Dataset.zip((valid_image_ds, valid_label_ds))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7w9LxzoqCcgV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Then we set the buffer size and the batch size for validation."
      ]
    },
    {
      "metadata": {
        "id": "o9uLXmdUCbrE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Prepare for validation\n",
        "va_ds = valid_image_label_ds.repeat()\n",
        "va_ds = va_ds.shuffle(buffer_size=1000)\n",
        "va_ds = va_ds.batch(BATCH_SIZE)\n",
        "va_ds = va_ds.prefetch(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GbUrb1wTCgHr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#MobileNetV2"
      ]
    },
    {
      "metadata": {
        "id": "7kOzNQdjCiJD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here we use Keras functional API to implement MobileNetV2 as our model."
      ]
    },
    {
      "metadata": {
        "id": "wTge-4TtCe1M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ConvBNReLU(inputs, o, kernel_size=3, strides=1, dwise=False, bn=True, relu=True):\n",
        "    padding = 'same'\n",
        "    if dwise:\n",
        "        x = DepthwiseConv2D(kernel_size=kernel_size, padding=padding, strides=strides, use_bias=not bn)(inputs)\n",
        "    else:\n",
        "        x = Conv2D(o, kernel_size=kernel_size, padding=padding, strides=strides, use_bias=not bn)(inputs)\n",
        "\n",
        "    if bn:\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "    if relu:\n",
        "        x = ReLU()(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def BottleNeck(inputs, i, o, expansion, strides):\n",
        "    add_residual = strides == 1 and i == o\n",
        "    x = ConvBNReLU(inputs, i*expansion, kernel_size=1)\n",
        "    x = ConvBNReLU(x, i*expansion, strides=strides, dwise=True)\n",
        "    x = ConvBNReLU(x, o, kernel_size=1, relu=False)\n",
        "    \n",
        "    if add_residual:\n",
        "        x = Add()([x, inputs])\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def MobileNetV2(inputs, n_classes, width_multiplier=1.):\n",
        "    bottleneck_params = [\n",
        "        # t, c, n, s\n",
        "        [1, 16, 1, 1],\n",
        "        [6, 24, 2, 2],\n",
        "        [6, 32, 3, 2],\n",
        "        [6, 64, 4, 2],\n",
        "        [6, 96, 3, 1],\n",
        "        [6, 160, 3, 2],\n",
        "        [6, 320, 1, 1],\n",
        "    ]\n",
        "\n",
        "    input_channel = int(32*width_multiplier)\n",
        "    for param in bottleneck_params:\n",
        "        param[1] = int(param[1]*width_multiplier)\n",
        "\n",
        "    x = ConvBNReLU(inputs, input_channel, strides=2)\n",
        "\n",
        "    for (t, c, n, s) in bottleneck_params:\n",
        "        x = BottleNeck(x, input_channel, c, t, s)\n",
        "        for _ in range(n-1):\n",
        "            x = BottleNeck(x, c, c, t, 1)\n",
        "        input_channel = c\n",
        "\n",
        "    x = ConvBNReLU(x, int(1280*width_multiplier), kernel_size=1)\n",
        "    x = AveragePooling2D(pool_size=7, padding='same')(x)\n",
        "    x = Flatten()(x)\n",
        "    out = Dense(n_classes, activation='softmax')(x)\n",
        "    \n",
        "    return tf.keras.Model(inputs=inputs, outputs=out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G1HxLLyNCmyg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The model will take inputs of the shape [N, 224, 224, 3] and outputs probabilities of the shape [N, 24], where N is the batch size."
      ]
    },
    {
      "metadata": {
        "id": "pNW-RMX2Cj3H",
        "colab_type": "code",
        "outputId": "94f37ad6-c1ac-4a39-fa12-165d9c8ab4cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5702
        }
      },
      "cell_type": "code",
      "source": [
        "model = MobileNetV2(Input(shape=(image_size,image_size,3)), len(alphabet2int))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 112, 112, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 112, 112, 32) 128         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu (ReLU)                    (None, 112, 112, 32) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 112, 112, 32) 1024        re_lu[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 112, 112, 32) 128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_1 (ReLU)                  (None, 112, 112, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d (DepthwiseConv (None, 112, 112, 32) 288         re_lu_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 112, 112, 32) 128         depthwise_conv2d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_2 (ReLU)                  (None, 112, 112, 32) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 112, 112, 16) 512         re_lu_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 112, 112, 16) 64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 112, 112, 96) 1536        batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 112, 112, 96) 384         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_3 (ReLU)                  (None, 112, 112, 96) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_1 (DepthwiseCo (None, 56, 56, 96)   864         re_lu_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 56, 56, 96)   384         depthwise_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_4 (ReLU)                  (None, 56, 56, 96)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 56, 56, 24)   2304        re_lu_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 56, 56, 24)   96          conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 56, 56, 144)  3456        batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 56, 56, 144)  576         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_5 (ReLU)                  (None, 56, 56, 144)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_2 (DepthwiseCo (None, 56, 56, 144)  1296        re_lu_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 56, 56, 144)  576         depthwise_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_6 (ReLU)                  (None, 56, 56, 144)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 56, 56, 24)   3456        re_lu_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 56, 56, 24)   96          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 56, 56, 24)   0           batch_normalization_9[0][0]      \n",
            "                                                                 batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 56, 56, 144)  3456        add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 56, 56, 144)  576         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_7 (ReLU)                  (None, 56, 56, 144)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_3 (DepthwiseCo (None, 28, 28, 144)  1296        re_lu_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 28, 28, 144)  576         depthwise_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_8 (ReLU)                  (None, 28, 28, 144)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 28, 28, 32)   4608        re_lu_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 28, 28, 32)   128         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 28, 28, 192)  6144        batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 28, 28, 192)  768         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_9 (ReLU)                  (None, 28, 28, 192)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_4 (DepthwiseCo (None, 28, 28, 192)  1728        re_lu_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 28, 28, 192)  768         depthwise_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_10 (ReLU)                 (None, 28, 28, 192)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 28, 28, 32)   6144        re_lu_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 28, 28, 32)   128         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 28, 28, 32)   0           batch_normalization_15[0][0]     \n",
            "                                                                 batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 28, 28, 192)  6144        add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 28, 28, 192)  768         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_11 (ReLU)                 (None, 28, 28, 192)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_5 (DepthwiseCo (None, 28, 28, 192)  1728        re_lu_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 28, 28, 192)  768         depthwise_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_12 (ReLU)                 (None, 28, 28, 192)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 28, 28, 32)   6144        re_lu_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 28, 28, 32)   128         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 28, 28, 32)   0           batch_normalization_18[0][0]     \n",
            "                                                                 add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 28, 28, 192)  6144        add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 28, 28, 192)  768         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_13 (ReLU)                 (None, 28, 28, 192)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_6 (DepthwiseCo (None, 14, 14, 192)  1728        re_lu_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 14, 14, 192)  768         depthwise_conv2d_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_14 (ReLU)                 (None, 14, 14, 192)  0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 14, 14, 64)   12288       re_lu_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 14, 14, 64)   256         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 14, 14, 384)  24576       batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 14, 14, 384)  1536        conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_15 (ReLU)                 (None, 14, 14, 384)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_7 (DepthwiseCo (None, 14, 14, 384)  3456        re_lu_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 14, 14, 384)  1536        depthwise_conv2d_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_16 (ReLU)                 (None, 14, 14, 384)  0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 14, 14, 64)   24576       re_lu_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 14, 14, 64)   256         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 14, 14, 64)   0           batch_normalization_24[0][0]     \n",
            "                                                                 batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 14, 14, 384)  24576       add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 14, 14, 384)  1536        conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_17 (ReLU)                 (None, 14, 14, 384)  0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_8 (DepthwiseCo (None, 14, 14, 384)  3456        re_lu_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 14, 14, 384)  1536        depthwise_conv2d_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_18 (ReLU)                 (None, 14, 14, 384)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 14, 14, 64)   24576       re_lu_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 14, 14, 64)   256         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 14, 14, 64)   0           batch_normalization_27[0][0]     \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 14, 14, 384)  24576       add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 14, 14, 384)  1536        conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_19 (ReLU)                 (None, 14, 14, 384)  0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_9 (DepthwiseCo (None, 14, 14, 384)  3456        re_lu_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 14, 14, 384)  1536        depthwise_conv2d_9[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_20 (ReLU)                 (None, 14, 14, 384)  0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 14, 14, 64)   24576       re_lu_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 14, 14, 64)   256         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 14, 14, 64)   0           batch_normalization_30[0][0]     \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 14, 14, 384)  24576       add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 14, 14, 384)  1536        conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_21 (ReLU)                 (None, 14, 14, 384)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_10 (DepthwiseC (None, 14, 14, 384)  3456        re_lu_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 14, 14, 384)  1536        depthwise_conv2d_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_22 (ReLU)                 (None, 14, 14, 384)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 14, 14, 96)   36864       re_lu_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 14, 14, 96)   384         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 14, 14, 576)  55296       batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 14, 14, 576)  2304        conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_23 (ReLU)                 (None, 14, 14, 576)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_11 (DepthwiseC (None, 14, 14, 576)  5184        re_lu_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 14, 14, 576)  2304        depthwise_conv2d_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_24 (ReLU)                 (None, 14, 14, 576)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 14, 14, 96)   55296       re_lu_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 14, 14, 96)   384         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 14, 14, 96)   0           batch_normalization_36[0][0]     \n",
            "                                                                 batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 14, 14, 576)  55296       add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 14, 14, 576)  2304        conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_25 (ReLU)                 (None, 14, 14, 576)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_12 (DepthwiseC (None, 14, 14, 576)  5184        re_lu_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 14, 14, 576)  2304        depthwise_conv2d_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_26 (ReLU)                 (None, 14, 14, 576)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 14, 14, 96)   55296       re_lu_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 14, 14, 96)   384         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 14, 14, 96)   0           batch_normalization_39[0][0]     \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 14, 14, 576)  55296       add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 14, 14, 576)  2304        conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_27 (ReLU)                 (None, 14, 14, 576)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_13 (DepthwiseC (None, 7, 7, 576)    5184        re_lu_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 576)    2304        depthwise_conv2d_13[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_28 (ReLU)                 (None, 7, 7, 576)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 7, 7, 160)    92160       re_lu_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    640         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 960)    153600      batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 960)    3840        conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_29 (ReLU)                 (None, 7, 7, 960)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_14 (DepthwiseC (None, 7, 7, 960)    8640        re_lu_29[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 960)    3840        depthwise_conv2d_14[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_30 (ReLU)                 (None, 7, 7, 960)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 160)    153600      re_lu_30[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    640         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "                                                                 batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 960)    153600      add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 960)    3840        conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_31 (ReLU)                 (None, 7, 7, 960)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_15 (DepthwiseC (None, 7, 7, 960)    8640        re_lu_31[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 960)    3840        depthwise_conv2d_15[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_32 (ReLU)                 (None, 7, 7, 960)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 160)    153600      re_lu_32[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 160)    640         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 7, 7, 160)    0           batch_normalization_48[0][0]     \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 960)    153600      add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 960)    3840        conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_33 (ReLU)                 (None, 7, 7, 960)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "depthwise_conv2d_16 (DepthwiseC (None, 7, 7, 960)    8640        re_lu_33[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 960)    3840        depthwise_conv2d_16[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_34 (ReLU)                 (None, 7, 7, 960)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 320)    307200      re_lu_34[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 320)    1280        conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 1280)   409600      batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 1280)   5120        conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_35 (ReLU)                 (None, 7, 7, 1280)   0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 1, 1, 1280)   0           re_lu_35[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 1280)         0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 24)           30744       flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 2,289,880\n",
            "Trainable params: 2,255,704\n",
            "Non-trainable params: 34,176\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m2FOvR-6Ct0j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Training the Model"
      ]
    },
    {
      "metadata": {
        "id": "awIDCqtdC1IL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We compile the model with `Adam` optimizer with 0.001 learning rate and `sparse_catergorical_crossentropy` loss. The model will be saved after every epoch via `tf.keras.callbacks.ModelCheckpoint`."
      ]
    },
    {
      "metadata": {
        "id": "1I04ZVBICp3r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Compile the model with Adam optimizer\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "!mkdir training_checkpoints\n",
        "\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"{epoch:02d}-{val_loss:.3f}-{val_acc:.3f}.hdf5\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6vNVxY6oC6yy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Letâ€™s say we would like to train the model for 30 epochs. Each epoch takes around 30 seconds with GPU on Colab, so 30 epochs only take 15 to 20 minutes in total. We should notice that the batch size is 32 here."
      ]
    },
    {
      "metadata": {
        "id": "FH9NTZrgC4qs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "steps_per_epoch = n_train // BATCH_SIZE if n_train % BATCH_SIZE == 0 else n_train // BATCH_SIZE + 1 # 75 steps\n",
        "validation_steps = n_valid // BATCH_SIZE if n_valid % BATCH_SIZE == 0 else n_valid // BATCH_SIZE + 1 # 19 steps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ErYh68-qC-ib",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Below are the codes for model training using Keras Model `fit` method."
      ]
    },
    {
      "metadata": {
        "id": "LJPXKoWjC85l",
        "colab_type": "code",
        "outputId": "2cf19fce-bfcc-43f7-96d1-dfc0d3a6f28e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1054
        }
      },
      "cell_type": "code",
      "source": [
        "model_histroy = model.fit(\n",
        "    tr_ds.make_one_shot_iterator(),\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=va_ds.make_one_shot_iterator(),\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=[checkpoint_callback],\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "75/75 [==============================] - 120s 2s/step - loss: 2.8253 - acc: 0.1296 - val_loss: 3.3183 - val_acc: 0.0461\n",
            "Epoch 2/30\n",
            "75/75 [==============================] - 37s 489ms/step - loss: 2.2064 - acc: 0.2742 - val_loss: 3.5714 - val_acc: 0.0428\n",
            "Epoch 3/30\n",
            "75/75 [==============================] - 37s 487ms/step - loss: 1.7775 - acc: 0.4004 - val_loss: 4.3528 - val_acc: 0.0296\n",
            "Epoch 4/30\n",
            "75/75 [==============================] - 36s 484ms/step - loss: 1.4525 - acc: 0.5104 - val_loss: 5.0168 - val_acc: 0.0461\n",
            "Epoch 5/30\n",
            "75/75 [==============================] - 36s 485ms/step - loss: 1.1041 - acc: 0.6342 - val_loss: 5.8557 - val_acc: 0.0362\n",
            "Epoch 6/30\n",
            "75/75 [==============================] - 36s 486ms/step - loss: 0.9063 - acc: 0.6988 - val_loss: 4.9600 - val_acc: 0.0428\n",
            "Epoch 7/30\n",
            "75/75 [==============================] - 36s 483ms/step - loss: 0.7291 - acc: 0.7554 - val_loss: 5.6969 - val_acc: 0.0477\n",
            "Epoch 8/30\n",
            "75/75 [==============================] - 36s 485ms/step - loss: 0.5594 - acc: 0.8150 - val_loss: 2.9659 - val_acc: 0.2056\n",
            "Epoch 9/30\n",
            "75/75 [==============================] - 36s 483ms/step - loss: 0.5448 - acc: 0.8217 - val_loss: 2.1051 - val_acc: 0.4326\n",
            "Epoch 10/30\n",
            "75/75 [==============================] - 36s 486ms/step - loss: 0.4570 - acc: 0.8542 - val_loss: 2.0251 - val_acc: 0.4556\n",
            "Epoch 11/30\n",
            "75/75 [==============================] - 36s 483ms/step - loss: 0.3754 - acc: 0.8788 - val_loss: 4.4726 - val_acc: 0.2878\n",
            "Epoch 12/30\n",
            "75/75 [==============================] - 36s 484ms/step - loss: 0.3400 - acc: 0.8871 - val_loss: 3.3083 - val_acc: 0.3931\n",
            "Epoch 13/30\n",
            "75/75 [==============================] - 36s 483ms/step - loss: 0.2789 - acc: 0.9117 - val_loss: 2.0923 - val_acc: 0.5132\n",
            "Epoch 14/30\n",
            "75/75 [==============================] - 36s 484ms/step - loss: 0.2196 - acc: 0.9271 - val_loss: 1.6254 - val_acc: 0.5576\n",
            "Epoch 15/30\n",
            "75/75 [==============================] - 36s 485ms/step - loss: 0.2626 - acc: 0.9121 - val_loss: 3.7146 - val_acc: 0.4984\n",
            "Epoch 16/30\n",
            "75/75 [==============================] - 36s 483ms/step - loss: 0.2037 - acc: 0.9342 - val_loss: 1.4638 - val_acc: 0.6891\n",
            "Epoch 17/30\n",
            "75/75 [==============================] - 36s 486ms/step - loss: 0.1877 - acc: 0.9383 - val_loss: 2.2516 - val_acc: 0.5510\n",
            "Epoch 18/30\n",
            "75/75 [==============================] - 36s 483ms/step - loss: 0.2022 - acc: 0.9367 - val_loss: 2.6154 - val_acc: 0.5263\n",
            "Epoch 19/30\n",
            "75/75 [==============================] - 36s 486ms/step - loss: 0.1369 - acc: 0.9567 - val_loss: 2.2707 - val_acc: 0.5444\n",
            "Epoch 20/30\n",
            "75/75 [==============================] - 36s 484ms/step - loss: 0.1367 - acc: 0.9513 - val_loss: 1.9673 - val_acc: 0.5707\n",
            "Epoch 21/30\n",
            "75/75 [==============================] - 36s 484ms/step - loss: 0.1812 - acc: 0.9396 - val_loss: 2.8146 - val_acc: 0.5592\n",
            "Epoch 22/30\n",
            "75/75 [==============================] - 36s 484ms/step - loss: 0.1552 - acc: 0.9508 - val_loss: 3.5913 - val_acc: 0.4507\n",
            "Epoch 23/30\n",
            "75/75 [==============================] - 36s 483ms/step - loss: 0.1614 - acc: 0.9488 - val_loss: 2.3933 - val_acc: 0.5757\n",
            "Epoch 24/30\n",
            "75/75 [==============================] - 36s 483ms/step - loss: 0.0930 - acc: 0.9717 - val_loss: 1.9335 - val_acc: 0.5987\n",
            "Epoch 25/30\n",
            "75/75 [==============================] - 36s 484ms/step - loss: 0.0895 - acc: 0.9729 - val_loss: 1.6373 - val_acc: 0.6513\n",
            "Epoch 26/30\n",
            "75/75 [==============================] - 36s 483ms/step - loss: 0.1005 - acc: 0.9721 - val_loss: 2.7241 - val_acc: 0.6003\n",
            "Epoch 27/30\n",
            "75/75 [==============================] - 36s 485ms/step - loss: 0.1076 - acc: 0.9642 - val_loss: 1.8193 - val_acc: 0.6908\n",
            "Epoch 28/30\n",
            "75/75 [==============================] - 36s 486ms/step - loss: 0.0858 - acc: 0.9742 - val_loss: 2.9073 - val_acc: 0.5543\n",
            "Epoch 29/30\n",
            "75/75 [==============================] - 36s 483ms/step - loss: 0.0916 - acc: 0.9688 - val_loss: 1.1968 - val_acc: 0.7023\n",
            "Epoch 30/30\n",
            "75/75 [==============================] - 36s 485ms/step - loss: 0.1342 - acc: 0.9521 - val_loss: 1.5070 - val_acc: 0.6414\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TJm1AURlDRwb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "After only 30-epoch training, the model can achieve about 60% validation accuracy. You are encouraged to train the model for more epochs. The model in the demo achieved about 80% validation accuracy after 100-epoch training, and it took less than an hour!"
      ]
    },
    {
      "metadata": {
        "id": "63Gs9swkDXmx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Convert the Model"
      ]
    },
    {
      "metadata": {
        "id": "ZDO3HDgnDaxB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This section will introduce how to install TensorFLow.js and how to save the Keras model in TensorFlow.js Layers format for web application.\n",
        "\n",
        "First, we should restart the Colab runtime. Then we install Tensorflow.js on Colab using `pip`."
      ]
    },
    {
      "metadata": {
        "id": "1vs2gA0iDBoJ",
        "colab_type": "code",
        "outputId": "b4c3e030-9e29-495e-f9e9-6753f333e8a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1178
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflowjs\n",
            "  Downloading https://files.pythonhosted.org/packages/6b/0c/89f4b64a9c55a161287781f8c63e4492f6cb2faa01195c9f8990291c1404/tensorflowjs-0.8.0-py3-none-any.whl\n",
            "Collecting keras==2.2.2 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/7d/b1dedde8af99bd82f20ed7e9697aac0597de3049b1f786aa2aac3b9bd4da/Keras-2.2.2-py2.py3-none-any.whl (299kB)\n",
            "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307kB 25.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six==1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.11.0)\n",
            "Collecting tensorflow-hub==0.1.1 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/22/64f246ef80e64b1a13b2f463cefa44f397a51c49a303294f5f3d04ac39ac/tensorflow_hub-0.1.1-py2.py3-none-any.whl (52kB)\n",
            "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 7.8MB/s \n",
            "\u001b[?25hCollecting numpy==1.15.1 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/94/7049fed8373c52839c8cde619acaf2c9b83082b935e5aa8c0fa27a4a8bcc/numpy-1.15.1-cp36-cp36m-manylinux1_x86_64.whl (13.9MB)\n",
            "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13.9MB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py==2.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.8.0)\n",
            "Collecting tensorflow==1.12.0 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cc/ca70b78087015d21c5f3f93694107f34ebccb3be9624385a911d4b52ecef/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl (83.1MB)\n",
            "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83.1MB 389kB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2->tensorflowjs) (3.13)\n",
            "Collecting keras-applications==1.0.4 (from keras==2.2.2->tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/90/8f327deaa37a71caddb59b7b4aaa9d4b3e90c0e76f8c2d1572005278ddc5/Keras_Applications-1.0.4-py2.py3-none-any.whl (43kB)\n",
            "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51kB 19.5MB/s \n",
            "\u001b[?25hCollecting keras-preprocessing==1.0.2 (from keras==2.2.2->tensorflowjs)\n",
            "  Downloading https://files.pythonhosted.org/packages/71/26/1e778ebd737032749824d5cba7dbd3b0cf9234b87ab5ec79f5f0403ca7e9/Keras_Preprocessing-1.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub==0.1.1->tensorflowjs) (3.6.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.32.3)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.7.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.7.0)\n",
            "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (1.12.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow-hub==0.1.1->tensorflowjs) (40.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->tensorflowjs) (3.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->tensorflowjs) (0.14.1)\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mthinc 6.12.1 has requirement wrapt<1.11.0,>=1.10.0, but you'll have wrapt 1.11.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mtensorflow 1.12.0 has requirement keras-applications>=1.0.6, but you'll have keras-applications 1.0.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mtensorflow 1.12.0 has requirement keras-preprocessing>=1.0.5, but you'll have keras-preprocessing 1.0.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mpymc3 3.6 has requirement joblib<0.13.0, but you'll have joblib 0.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mfeaturetools 0.4.1 has requirement pandas>=0.23.0, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mcufflinks 0.14.6 has requirement plotly>=3.0.0, but you'll have plotly 1.12.12 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, keras-applications, keras-preprocessing, keras, tensorflow-hub, tensorflow, tensorflowjs\n",
            "  Found existing installation: numpy 1.14.6\n",
            "    Uninstalling numpy-1.14.6:\n",
            "      Successfully uninstalled numpy-1.14.6\n",
            "  Found existing installation: Keras-Applications 1.0.7\n",
            "    Uninstalling Keras-Applications-1.0.7:\n",
            "      Successfully uninstalled Keras-Applications-1.0.7\n",
            "  Found existing installation: Keras-Preprocessing 1.0.9\n",
            "    Uninstalling Keras-Preprocessing-1.0.9:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.0.9\n",
            "  Found existing installation: Keras 2.2.4\n",
            "    Uninstalling Keras-2.2.4:\n",
            "      Successfully uninstalled Keras-2.2.4\n",
            "  Found existing installation: tensorflow-hub 0.2.0\n",
            "    Uninstalling tensorflow-hub-0.2.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.2.0\n",
            "  Found existing installation: tensorflow 1.13.0rc1\n",
            "    Uninstalling tensorflow-1.13.0rc1:\n",
            "      Successfully uninstalled tensorflow-1.13.0rc1\n",
            "Successfully installed keras-2.2.2 keras-applications-1.0.4 keras-preprocessing-1.0.2 numpy-1.15.1 tensorflow-1.12.0 tensorflow-hub-0.1.1 tensorflowjs-0.8.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "8tC-ulVtEUAH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we run the same codes in [Preparing the Data](#Preparing-the-Data) and [MobileNetV2](#MobileNetV2) sections. Then we take a look at the training checkpoints."
      ]
    },
    {
      "metadata": {
        "id": "u7YOFgPJEUj-",
        "colab_type": "code",
        "outputId": "9fb0a069-ab36-4a2f-a4a3-365c91c5a679",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "cell_type": "code",
      "source": [
        "!ls training_checkpoints/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "01-3.318-0.046.hdf5  11-4.473-0.288.hdf5  21-2.815-0.559.hdf5\n",
            "02-3.571-0.043.hdf5  12-3.308-0.393.hdf5  22-3.591-0.451.hdf5\n",
            "03-4.353-0.030.hdf5  13-2.092-0.513.hdf5  23-2.393-0.576.hdf5\n",
            "04-5.017-0.046.hdf5  14-1.625-0.558.hdf5  24-1.934-0.599.hdf5\n",
            "05-5.856-0.036.hdf5  15-3.715-0.498.hdf5  25-1.637-0.651.hdf5\n",
            "06-4.960-0.043.hdf5  16-1.464-0.689.hdf5  26-2.724-0.600.hdf5\n",
            "07-5.697-0.048.hdf5  17-2.252-0.551.hdf5  27-1.819-0.691.hdf5\n",
            "08-2.966-0.206.hdf5  18-2.615-0.526.hdf5  28-2.907-0.554.hdf5\n",
            "09-2.105-0.433.hdf5  19-2.271-0.544.hdf5  29-1.197-0.702.hdf5\n",
            "10-2.025-0.456.hdf5  20-1.967-0.571.hdf5  30-1.507-0.641.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_eIS3OfgEXy3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can pick one of the checkpoints and load its weights. Here we pick the one with the best validation accuracy (the last float number in the file name):"
      ]
    },
    {
      "metadata": {
        "id": "w1F6PaA2EZ71",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.load_weights('training_checkpoints/29-1.197-0.702.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X7iaKQ_XEcrC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The following codes show how to save the metadata and the Keras model in TensorFlow.js Layers format in the `model_js` folder."
      ]
    },
    {
      "metadata": {
        "id": "0rcYR9PAEn4e",
        "colab_type": "code",
        "outputId": "64c9cd11-a339-4413-f67c-22a867de5756",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "import tensorflowjs as tfjs\n",
        "MODEL_DIR = 'model_js'\n",
        "if not os.path.exists(MODEL_DIR): \n",
        "    os.mkdir(MODEL_DIR)\n",
        "\n",
        "metadata = {\n",
        "    'alphabet2int': alphabet2int,\n",
        "    'int2alphabet': int2alphabet,\n",
        "    'image_size': image_size,\n",
        "    'RGB_mean': list(RGB_mean)\n",
        "}\n",
        "\n",
        "metadata_json_path = os.path.join(MODEL_DIR, 'metadata.json')\n",
        "json.dump(metadata, open(metadata_json_path, 'wt'))\n",
        "tfjs.converters.save_keras_model(model, MODEL_DIR)\n",
        "\n",
        "!ls model_js"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "group1-shard1of3  group1-shard2of3  group1-shard3of3  metadata.json  model.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ldp7QgS_ErEF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The `model_js` folder contains 5 files: (1) `model.json` (model architecture); (2) 3 `group1-shardXof3` files (model weights); (3) `metadata.json` (metadata). Then we compress the `model_js` folder and download it to the local file system."
      ]
    },
    {
      "metadata": {
        "id": "IonwocztEu9P",
        "colab_type": "code",
        "outputId": "7a7bf900-f4fd-4840-d77c-d7e08fcf85fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "!zip -r model_js.zip model_js\n",
        "\n",
        "from google.colab import files\n",
        "downloaded = files.download('model_js.zip')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: model_js/ (stored 0%)\n",
            "  adding: model_js/metadata.json (deflated 55%)\n",
            "  adding: model_js/group1-shard3of3 (deflated 8%)\n",
            "  adding: model_js/model.json (deflated 96%)\n",
            "  adding: model_js/group1-shard1of3 (deflated 8%)\n",
            "  adding: model_js/group1-shard2of3 (deflated 8%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ar9swd4Enuoo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}